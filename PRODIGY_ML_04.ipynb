{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1TZqk8LKVel4bWassHJArJel9r6ihZjro","authorship_tag":"ABX9TyMEwiNKFejCke4thbXme7Sr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **QNS> Develop a hand gesture recognition model that can accurately identify and classify different hand gestures from image or video data, enabling intuitive human-computer interaction and gesture-based control systems.**"],"metadata":{"id":"6hVDALMFjPXq"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"Phqow1tIi6e7","executionInfo":{"status":"ok","timestamp":1713704319089,"user_tz":-330,"elapsed":68589,"user":{"displayName":"Sourish Chatterjee","userId":"07885744711931225299"}}},"outputs":[],"source":["# Example code for data collection\n","# Assuming you have a dataset directory with subdirectories for each class\n","\n","import os\n","import cv2\n","\n","dataset_dir = '/content/drive/MyDrive/handrec'\n","\n","def load_dataset(dataset_dir):\n","    images = []\n","    labels = []\n","    for label in os.listdir(dataset_dir):\n","        label_dir = os.path.join(dataset_dir, label)\n","        for image_file in os.listdir(label_dir):\n","            image_path = os.path.join(label_dir, image_file)\n","            image = cv2.imread(image_path)\n","            images.append(image)\n","            labels.append(label)\n","    return images, labels\n","\n","images, labels = load_dataset(dataset_dir)"]},{"cell_type":"code","source":["# Example code for data preprocessing\n","# Assuming you have loaded images and labels\n","\n","import numpy as np\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","\n","def preprocess_data(images, labels):\n","    images = np.array(images)\n","    labels = np.array(labels)\n","    # Convert labels to numerical values\n","    label_encoder = LabelEncoder()\n","    labels = label_encoder.fit_transform(labels)\n","    # Normalize images\n","    images = images / 255.0\n","    # Split dataset into train and test sets\n","    X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.3, random_state=0)\n","    return X_train, X_test, y_train, y_test\n","\n","X_train, X_test, y_train, y_test = preprocess_data(images, labels)"],"metadata":{"id":"uPAhCP5mqtTu","executionInfo":{"status":"ok","timestamp":1713704337889,"user_tz":-330,"elapsed":7437,"user":{"displayName":"Sourish Chatterjee","userId":"07885744711931225299"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Example code for model training\n","# Assuming you have preprocessed train and test sets\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n","\n","image_height, image_width = X_train.shape[1], X_train.shape[2]  # Assuming images are already preprocessed\n","num_classes = len(np.unique(y_train))  # Number of unique classes in the dataset\n","\n","model = Sequential([\n","    Conv2D(32, (3, 3), activation='relu', input_shape=(image_height, image_width, 3)),\n","    MaxPooling2D((2, 2)),\n","    Conv2D(64, (3, 3), activation='relu'),\n","    MaxPooling2D((2, 2)),\n","    Flatten(),\n","    Dense(64, activation='relu'),\n","    Dense(num_classes, activation='softmax')\n","])\n","\n","model.compile(optimizer='adam',\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C5CyCs_KAJ_O","executionInfo":{"status":"ok","timestamp":1713704921115,"user_tz":-330,"elapsed":569868,"user":{"displayName":"Sourish Chatterjee","userId":"07885744711931225299"}},"outputId":"f41027d3-c627-4646-8727-09743ad909b0"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","44/44 [==============================] - 56s 1s/step - loss: 0.7535 - accuracy: 0.8543 - val_loss: 9.7483e-04 - val_accuracy: 1.0000\n","Epoch 2/10\n","44/44 [==============================] - 53s 1s/step - loss: 0.0165 - accuracy: 0.9957 - val_loss: 0.0013 - val_accuracy: 1.0000\n","Epoch 3/10\n","44/44 [==============================] - 53s 1s/step - loss: 3.1304e-04 - accuracy: 1.0000 - val_loss: 1.2763e-04 - val_accuracy: 1.0000\n","Epoch 4/10\n","44/44 [==============================] - 53s 1s/step - loss: 5.3012e-05 - accuracy: 1.0000 - val_loss: 6.1756e-05 - val_accuracy: 1.0000\n","Epoch 5/10\n","44/44 [==============================] - 54s 1s/step - loss: 2.8151e-05 - accuracy: 1.0000 - val_loss: 3.6421e-05 - val_accuracy: 1.0000\n","Epoch 6/10\n","44/44 [==============================] - 54s 1s/step - loss: 1.7903e-05 - accuracy: 1.0000 - val_loss: 2.6318e-05 - val_accuracy: 1.0000\n","Epoch 7/10\n","44/44 [==============================] - 54s 1s/step - loss: 1.2968e-05 - accuracy: 1.0000 - val_loss: 1.9373e-05 - val_accuracy: 1.0000\n","Epoch 8/10\n","44/44 [==============================] - 54s 1s/step - loss: 9.8857e-06 - accuracy: 1.0000 - val_loss: 1.4876e-05 - val_accuracy: 1.0000\n","Epoch 9/10\n","44/44 [==============================] - 55s 1s/step - loss: 7.7673e-06 - accuracy: 1.0000 - val_loss: 1.2132e-05 - val_accuracy: 1.0000\n","Epoch 10/10\n","44/44 [==============================] - 55s 1s/step - loss: 6.3229e-06 - accuracy: 1.0000 - val_loss: 1.0153e-05 - val_accuracy: 1.0000\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7c513be49480>"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["# Example code for model evaluation\n","# Assuming you have a trained model and test set\n","\n","loss, accuracy = model.evaluate(X_test, y_test)\n","print(f'Test Loss: {loss}')\n","print(f'Test Accuracy: {accuracy}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pdTC8q_Q2z5l","executionInfo":{"status":"ok","timestamp":1713704940859,"user_tz":-330,"elapsed":6369,"user":{"displayName":"Sourish Chatterjee","userId":"07885744711931225299"}},"outputId":"902b13b0-ef92-4747-a1a6-1bf998e54d3d"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["19/19 [==============================] - 4s 208ms/step - loss: 1.0153e-05 - accuracy: 1.0000\n","Test Loss: 1.01531004474964e-05\n","Test Accuracy: 1.0\n"]}]}]}